# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## –û –ø—Ä–æ–µ–∫—Ç–µ

Domain-Specific MoE System - **—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã** —Å–∏—Å—Ç–µ–º—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –Ω–∞ –±–∞–∑–µ Mixture of Experts (MoE). –ü—Ä–æ–µ–∫—Ç –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ —Å—Ç–∞–¥–∏–∏ –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–¥—Ö–æ–¥–æ–≤.

### –¢–µ–∫—É—â–∏–π —Ñ–æ–∫—É—Å
- –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã AI –º–æ–¥–µ–ª–∏ –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á
- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å–∏—Å—Ç–µ–º—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (MoE)
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π –∏ –ø–æ–¥—Ö–æ–¥–æ–≤
- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –∏ –æ–±—â–µ–Ω–∏—è —Å –º–æ–¥–µ–ª—å—é
- –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á

### –ë—É–¥—É—â–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
–†–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞, embodied AI –∏ hardware –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∑–∞–ª–æ–∂–µ–Ω—ã –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∫–∞–∫ –±—É–¥—É—â–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è –ø—Ä–æ–µ–∫—Ç–∞.

**–í—Å–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –æ–±—â–µ–Ω–∏–µ –≤–µ–¥—É—Ç—Å—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.**

## –ö–æ–Ω—Ü–µ–ø—Ü–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

### –ü–ª–∞–Ω–∏—Ä—É–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

```
Application Layer (Task Planning, Reasoning, Context Management)
       ‚Üì
Intelligence Layer (Router ‚Üí 64+ Domain Experts ‚Üí Response Generation)
       ‚Üì
[Future] Multimodal Layer (Vision, Audio, Motor - –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)
```

### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)

1. **Router System** - –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º—É —ç–∫—Å–ø–µ—Ä—Ç—É
   - Learned router (–Ω–µ–π—Ä–æ—Å–µ—Ç—å, –æ–±—É—á–∞–µ–º–∞—è)
   - Rule-based router (keywords/patterns)
   - Hierarchical router (–∫–∞—Ç–µ–≥–æ—Ä–∏—è ‚Üí —ç–∫—Å–ø–µ—Ä—Ç)

2. **Expert System** - —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
   - –ö–æ–Ω—Ü–µ–ø—Ü–∏—è: 64+ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –æ–±–ª–∞—Å—Ç—è–º (–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –Ω–∞—É–∫–∞, –∏ —Ç.–¥.)
   - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: —Ç–æ–ª—å–∫–æ 1-2B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∞–∫—Ç–∏–≤–Ω—ã (–∏–∑ 64B total)
   - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –∫–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä—Ç - –æ—Ç–¥–µ–ª—å–Ω–∞—è transformer –º–æ–¥–µ–ª—å
   - –ü–ª–∞–Ω–∏—Ä—É–µ–º–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ: `models/experts/{expert_id}/`

3. **Transformer Architecture** - –±–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
   - Multi-head attention
   - Feed-forward networks
   - Layer normalization
   - Residual connections
   - –ì–∏–±–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã: d_model (512-4096), n_layers (4-32), n_heads (8-64)

4. **3-—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏** (–∏–Ω–Ω–æ–≤–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞)
   - **–¢–µ–∫—É—â–∞—è –ø–∞–º—è—Ç—å** (250k —Ç–æ–∫–µ–Ω–æ–≤) - –∞–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –¥–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
   - **–£—Å—Ç–∞—Ä–µ–≤—à–∞—è –ø–∞–º—è—Ç—å** (250k —Ç–æ–∫–µ–Ω–æ–≤) - —Å–∂–∞—Ç–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å –∫–æ–º–ø—Ä–µ—Å—Å–∏–µ–π
   - **–î–æ–ª–≥–∞—è –ø–∞–º—è—Ç—å** (250k —Ç–æ–∫–µ–Ω–æ–≤) - –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π

   –û–±—â–∏–π –æ–±—ä—ë–º: 750k —Ç–æ–∫–µ–Ω–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (–ø–ª–∞–Ω–∏—Ä—É–µ–º–∞—è)

```
NM_LLM_Test_2/
‚îú‚îÄ‚îÄ docs/                          # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
‚îÇ   ‚îú‚îÄ‚îÄ Plans/                     # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–ª–∞–Ω—ã –∏ –¥–∏–∑–∞–π–Ω
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20260106_ARCHITECTURE.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20260106_README.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20260106_INSTALLATION.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 20260106_API_REFERENCE.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 20260106_HARDWARE_GUIDE.md
‚îÇ   ‚îú‚îÄ‚îÄ Progress/                  # –°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞ –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PROJECT_STATUS.md      # –ì–õ–ê–í–ù–´–ô —Ñ–∞–π–ª —Å—Ç–∞—Ç—É—Å–∞ –ø—Ä–æ–µ–∫—Ç–∞
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ Reports/                   # –û—Ç—á—ë—Ç—ã –ø–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ PROJECT_SUMMARY.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ EXPERT_MODEL_IMPLEMENTATION.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ROUTER_IMPLEMENTATION.md
‚îÇ   ‚îú‚îÄ‚îÄ EXPERT_MODEL.md            # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è ExpertModel
‚îÇ   ‚îú‚îÄ‚îÄ ROUTER.md                  # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Router
‚îÇ   ‚îî‚îÄ‚îÄ README.md                  # –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
‚îÇ
‚îú‚îÄ‚îÄ src/                           # –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformer.py         # –ë–∞–∑–æ–≤—ã–π transformer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ expert.py              # Expert –º–æ–¥–µ–ª—å
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ router.py              # Router –º–æ–¥–µ–ª—å
‚îÇ   ‚îú‚îÄ‚îÄ training/                  # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset.py
‚îÇ   ‚îú‚îÄ‚îÄ inference/                 # Inference pipeline
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engine.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generation.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # –£—Ç–∏–ª–∏—Ç—ã
‚îÇ
‚îú‚îÄ‚îÄ models/                        # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ experts/                   # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
‚îÇ
‚îú‚îÄ‚îÄ tests/                         # –¢–µ—Å—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ test_transformer.py
‚îÇ   ‚îú‚îÄ‚îÄ test_expert.py
‚îÇ   ‚îî‚îÄ‚îÄ test_router.py
‚îÇ
‚îú‚îÄ‚îÄ configs/                       # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
‚îÇ   ‚îú‚îÄ‚îÄ model_config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ training_config.yaml
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                     # Jupyter notebooks –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ architecture_exploration.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ expert_training.ipynb
‚îÇ
‚îî‚îÄ‚îÄ scripts/                       # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∫—Ä–∏–ø—Ç—ã
    ‚îú‚îÄ‚îÄ create_expert.py
    ‚îî‚îÄ‚îÄ train_model.py
```

## –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ –∫–æ–º–∞–Ω–¥—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
python -m venv venv
source venv/bin/activate  # Linux/Mac
# –∏–ª–∏ venv\Scripts\activate  # Windows

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∞–∑–æ–≤—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
pip install torch transformers
pip install pytest black flake8 mypy
pip install jupyter notebook
```

### –†–∞–±–æ—Ç–∞ —Å –º–æ–¥–µ–ª—è–º–∏ (–ø–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ –∫–æ–º–∞–Ω–¥—ã)

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞
python scripts/create_expert.py \
  --name python_expert \
  --domain "Python Programming" \
  --d_model 2048 \
  --n_layers 8

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
python scripts/train_model.py \
  --config configs/expert_config.yaml \
  --data data/training_data.jsonl \
  --epochs 10

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ inference
python scripts/test_inference.py \
  --model models/experts/python_expert \
  --prompt "Write a Python function"

# Benchmark –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
python scripts/benchmark.py --model models/experts/python_expert
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –∫–æ–¥)

```bash
# –¢–µ—Å—Ç—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
pytest tests/test_transformer.py -v

# –¢–µ—Å—Ç—ã —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
pytest tests/test_expert.py -v

# –¢–µ—Å—Ç—ã router
pytest tests/test_router.py -v

# –í—Å–µ —Ç–µ—Å—Ç—ã —Å coverage
pytest --cov=src tests/
```

### –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞

```bash
# –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
black src/ tests/

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∏–ª—è
flake8 src/ tests/

# Type checking
mypy src/

# Jupyter notebook –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
jupyter notebook notebooks/
```

## –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏

### –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏

–ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ —É–º–µ—Ç—å:

1. **–õ–æ–≥–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ**
   - –†–µ—à–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
   - –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –≤—ã–≤–æ–¥—ã –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
   - –ê–Ω–∞–ª–∏–∑ –∏ —Å–∏–Ω—Ç–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

2. **–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ**
   - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–∞—Ö
   - –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
   - –û—Ç–ª–∞–¥–∫–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–¥–∞

3. **–û–±—â–µ–Ω–∏–µ**
   - –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
   - –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ—Å–µ–¥—ã
   - –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã

4. **–û–±—É—á–µ–Ω–∏–µ**
   - –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –Ω–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º
   - Fine-tuning –Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–æ–º–µ–Ω–∞—Ö
   - Transfer learning –º–µ–∂–¥—É —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏

### –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

- –¢–æ—á–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏: >90%
- –ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞: compilable & functional
- Perplexity –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: <15
- –°–∫–æ—Ä–æ—Å—Ç—å inference: 100+ tokens/sec –Ω–∞ CPU

## –°—Ç–∞–Ω–¥–∞—Ä—Ç—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

### Python conventions

```python
# Type hints –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã
def process_input(text: str, max_tokens: int = 100) -> dict[str, any]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å.

    Args:
        text: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º: —Ç–µ–∫—Å—Ç, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, –≤—Ä–µ–º—è

    Example:
        >>> result = process_input("–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?", max_tokens=50)
        >>> print(result['text'])
    """
    pass

# –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö
class TransformerBlock(nn.Module):
    """
    –û–¥–∏–Ω –±–ª–æ–∫ transformer –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.

    –ü—Ä–∏–º–µ–Ω—è–µ—Ç multi-head attention –∏ feed-forward —Å–µ—Ç—å —Å residual connections.
    """

    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ transformer block.

        Args:
            x: –í—Ö–æ–¥–Ω—ã–µ embeddings [batch_size, seq_len, d_model]
            mask: Attention mask [batch_size, seq_len, seq_len]

        Returns:
            output: –í—ã—Ö–æ–¥–Ω—ã–µ embeddings [batch_size, seq_len, d_model]
        """
        # –í—ã—á–∏—Å–ª—è–µ–º self-attention
        attn_output = self.attention(x, x, x, mask)  # [batch, seq_len, d_model]
        x = self.norm1(x + attn_output)  # Residual + LayerNorm

        # Feed-forward network
        ffn_output = self.ffn(x)  # [batch, seq_len, d_model]
        output = self.norm2(x + ffn_output)  # Residual + LayerNorm

        return output
```

### Naming conventions

- **Classes**: `PascalCase` (TransformerBlock, ExpertManager, RouterNetwork)
- **Functions/methods**: `snake_case` (forward_pass, load_expert, compute_attention)
- **Constants**: `UPPER_CASE` (MAX_SEQ_LEN, NUM_EXPERTS, VOCAB_SIZE)
- **–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤**: –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ (`attention_weights`, `expert_logits`, `hidden_states`)

### –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ

```python
# –ü–ª–æ—Ö–æ - –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
# Calculate attention scores
attention = softmax(Q @ K.T / sqrt(d_k))

# –•–æ—Ä–æ—à–æ - –Ω–∞ —Ä—É—Å—Å–∫–æ–º —Å –ø–æ—è—Å–Ω–µ–Ω–∏–µ–º
# –í—ã—á–∏—Å–ª—è–µ–º attention scores —Å –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º –ø–æ sqrt(d_k)
# –§–æ—Ä–º—É–ª–∞: Attention(Q,K,V) = softmax(QK^T / ‚àöd_k)V
attention = softmax(Q @ K.T / sqrt(d_k))

# –û—Ç–ª–∏—á–Ω–æ - —Å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—è–º–∏
# –í—ã—á–∏—Å–ª—è–µ–º attention scores
# Q: [batch, num_heads, seq_len, d_k]
# K: [batch, num_heads, seq_len, d_k]
# –†–µ–∑—É–ª—å—Ç–∞—Ç: [batch, num_heads, seq_len, seq_len]
attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)
attention_weights = torch.softmax(attention_scores, dim=-1)
```

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è

### Transformer Architecture

–ë–∞–∑–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞:

```python
class ExpertModel(nn.Module):
    """
    –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –º–æ–¥–µ–ª—å –¥–ª—è domain-specific —ç–∫—Å–ø–µ—Ä—Ç–∞.

    –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
        d_model: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings (512, 1024, 2048, 4096)
        n_layers: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ transformer –±–ª–æ–∫–æ–≤ (4-32)
        n_heads: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ attention heads (8-64)
        d_ff: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å feed-forward —Å–ª–æ—è (–æ–±—ã—á–Ω–æ 4*d_model)
        vocab_size: —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è
        max_seq_len: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
```

### Router Architecture

–¢—Ä–∏ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:

1. **Learned Router** (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π)
```python
class LearnedRouter(nn.Module):
    """
    –ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π router, –æ–±—É—á–∞–µ–º—ã–π –Ω–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

    Input: —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å ‚Üí embeddings
    Output: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
    Selection: Top-K —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —Å –Ω–∞–∏–≤—ã—Å—à–∏–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏
    """
```

2. **Rule-Based Router**
```python
# –ü—Ä–∞–≤–∏–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ keywords
rules = {
    'python': ['python', '–∫–æ–¥', '—Ñ—É–Ω–∫—Ü–∏—è', '–∫–ª–∞—Å—Å'],
    'math': ['–∏–Ω—Ç–µ–≥—Ä–∞–ª', '–ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è', '—É—Ä–∞–≤–Ω–µ–Ω–∏–µ'],
    'science': ['—Ñ–∏–∑–∏–∫–∞', '—Ö–∏–º–∏—è', '—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç']
}
```

3. **Hierarchical Router**
```python
# –î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–µ–ª–µ–∫—Ü–∏—è
# –£—Ä–æ–≤–µ–Ω—å 1: –ö–∞—Ç–µ–≥–æ—Ä–∏—è (Programming, Math, Science, ...)
# –£—Ä–æ–≤–µ–Ω—å 2: –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
```

### Expert Storage (–ø–ª–∞–Ω–∏—Ä—É–µ–º–æ–µ)

```
models/experts/{expert_name}/
‚îú‚îÄ‚îÄ config.json          # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (d_model, n_layers, n_heads, etc.)
‚îú‚îÄ‚îÄ model.pt            # PyTorch checkpoint
‚îú‚îÄ‚îÄ model.onnx          # ONNX –≤–µ—Ä—Å–∏—è (–¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
‚îú‚îÄ‚îÄ tokenizer.json      # –¢–æ–∫–µ–Ω–∞–π–∑–µ—Ä
‚îî‚îÄ‚îÄ metadata.json       # –ú–µ—Ç—Ä–∏–∫–∏ (accuracy, perplexity, training info)
```

### Memory Management

–ö–æ–Ω—Ü–µ–ø—Ü–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏:

- **Lazy Loading**: —ç–∫—Å–ø–µ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
- **LRU Cache**: –º–∞–∫—Å–∏–º—É–º 2-3 —ç–∫—Å–ø–µ—Ä—Ç–∞ –≤ –ø–∞–º—è—Ç–∏
- **Offloading**: –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —ç–∫—Å–ø–µ—Ä—Ç—ã –≤—ã–≥—Ä—É–∂–∞—é—Ç—Å—è
- **–¶–µ–ª–µ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: <4GB RAM –Ω–∞ CPU

### Inference Pipeline

```
–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    ‚Üì
Tokenization
    ‚Üì
Memory Manager (—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ 3-—Ö —É—Ä–æ–≤–Ω–µ–π)
    ‚Üì
Router Selection (–≤—ã–±–æ—Ä —ç–∫—Å–ø–µ—Ä—Ç–∞)
    ‚Üì
Load Expert (–µ—Å–ª–∏ –Ω–µ –≤ –∫—ç—à–µ)
    ‚Üì
Expert Inference (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞)
    ‚Üì
Post-processing
    ‚Üì
Memory Update (–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –ø–∞–º—è—Ç–∏)
    ‚Üì
–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
```

### –°–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ (–¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑)

#### –ö–æ–Ω—Ü–µ–ø—Ü–∏—è 3-—É—Ä–æ–≤–Ω–µ–≤–æ–π –ø–∞–º—è—Ç–∏

**–ü—Ä–æ–±–ª–µ–º–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞:**
- –û–±—ã—á–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä (2k-32k —Ç–æ–∫–µ–Ω–æ–≤)
- –ü—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞ - —Å—Ç–∞—Ä–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–æ—Å—Ç–æ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è
- –ù–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ

**–†–µ—à–µ–Ω–∏–µ:**

```python
class ThreeLevelMemory:
    """
    3-—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

    –£—Ä–æ–≤–Ω–∏:
        1. –¢–µ–∫—É—â–∞—è –ø–∞–º—è—Ç—å (250k —Ç–æ–∫–µ–Ω–æ–≤) - –ø–æ–ª–Ω—ã–π –¥–µ—Ç–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        2. –£—Å—Ç–∞—Ä–µ–≤—à–∞—è –ø–∞–º—è—Ç—å (250k —Ç–æ–∫–µ–Ω–æ–≤) - —Å–∂–∞—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ
        3. –î–æ–ª–≥–∞—è –ø–∞–º—è—Ç—å (250k —Ç–æ–∫–µ–Ω–æ–≤) - –∫—Ä–∞—Ç–∫–∏–µ —Ä–µ–∑—é–º–µ

    –û–±—â–∏–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: 750k —Ç–æ–∫–µ–Ω–æ–≤ (–Ω–æ –Ω–µ –≤—Å–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è —Å—Ä–∞–∑—É!)
    """

    def __init__(self):
        self.current_memory = []      # –ü–æ–ª–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, 250k —Ç–æ–∫–µ–Ω–æ–≤
        self.obsolete_memory = []     # –°–∂–∞—Ç—ã–µ —Ä–µ–∑—é–º–µ, 250k —Ç–æ–∫–µ–Ω–æ–≤
        self.long_term_memory = []    # –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã, 250k —Ç–æ–∫–µ–Ω–æ–≤
```

#### –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –ë–ï–ó –∑–∞–º–µ–¥–ª–µ–Ω–∏—è:

**–ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è: –ù–ï –≤—Å—ë –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –≤ –º–æ–¥–µ–ª—å —Å—Ä–∞–∑—É!**

```python
def prepare_context_for_inference(self, current_query: str) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–º–Ω–æ, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å–µ 750k —Ç–æ–∫–µ–Ω–æ–≤.

    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
        1. –¢–µ–∫—É—â–∞—è –ø–∞–º—è—Ç—å: –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª–Ω–æ—Å—Ç—å—é (5-10k —Ç–æ–∫–µ–Ω–æ–≤)
        2. –£—Å—Ç–∞—Ä–µ–≤—à–∞—è –ø–∞–º—è—Ç—å: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–∂–∞—Ç—ã–µ –∫—É—Å–∫–∏ (2-5k —Ç–æ–∫–µ–Ω–æ–≤)
        3. –î–æ–ª–≥–∞—è –ø–∞–º—è—Ç—å: —Ç–æ–ª—å–∫–æ —Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ (1-2k —Ç–æ–∫–µ–Ω–æ–≤)

    –ò—Ç–æ–≥–æ: ~8-17k —Ç–æ–∫–µ–Ω–æ–≤ –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –≤ –º–æ–¥–µ–ª—å
           (–≤–º–µ—Å—Ç–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö 4-8k, –Ω–æ —Å –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–∏–º –æ—Ö–≤–∞—Ç–æ–º!)
    """

    # 1. –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª–Ω–æ—Å—Ç—å—é
    recent_context = self.current_memory[-10:]  # ~5-10k —Ç–æ–∫–µ–Ω–æ–≤

    # 2. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ —É—Å—Ç–∞—Ä–µ–≤—à–µ–π –ø–∞–º—è—Ç–∏
    relevant_obsolete = self.search_relevant(
        query=current_query,
        memory=self.obsolete_memory,
        max_tokens=3000
    )

    # 3. –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –∏–∑ –¥–æ–ª–≥–æ–π –ø–∞–º—è—Ç–∏
    important_longterm = self.get_important_facts(
        memory=self.long_term_memory,
        max_tokens=2000
    )

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º (total ~10-15k —Ç–æ–∫–µ–Ω–æ–≤)
    full_context = f"""
    [–í–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ –ø—Ä–æ—à–ª–æ–≥–æ]
    {important_longterm}

    [–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –Ω–µ–¥–∞–≤–Ω–µ–π –∏—Å—Ç–æ—Ä–∏–∏]
    {relevant_obsolete}

    [–¢–µ–∫—É—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä]
    {recent_context}

    [–ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å]
    {current_query}
    """

    return full_context
```

#### –ö–æ–º–ø—Ä–µ—Å—Å–∏—è –¥–ª—è —É—Å—Ç–∞—Ä–µ–≤—à–µ–π –ø–∞–º—è—Ç–∏

```python
def compress_to_obsolete_memory(self, old_messages: list) -> str:
    """
    –°–∂–∞—Ç–∏–µ —Å—Ç–∞—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ–º –≤ —É—Å—Ç–∞—Ä–µ–≤—à—É—é –ø–∞–º—è—Ç—å.

    –ú–µ—Ç–æ–¥—ã –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏:
        1. –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (—á–µ—Ä–µ–∑ –º–∞–ª—É—é –º–æ–¥–µ–ª—å-summarizer)
        2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤
        3. –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –∏ noise

    –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–∂–∞—Ç–∏—è: 5-10x
    –ü—Ä–∏–º–µ—Ä: 50k —Ç–æ–∫–µ–Ω–æ–≤ ‚Üí 5-10k —Ç–æ–∫–µ–Ω–æ–≤ —Å–∂–∞—Ç–æ–≥–æ —Ä–µ–∑—é–º–µ
    """

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—ë–≥–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (–Ω–µ –æ—Å–Ω–æ–≤–Ω—É—é!)
    summary = self.summarizer_model.summarize(old_messages)

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–∫—Ç—ã
    facts = self.extract_facts(old_messages)

    compressed = {
        'summary': summary,          # ~80% –æ–±—ä—ë–º–∞
        'key_facts': facts,          # ~20% –æ–±—ä—ë–º–∞
        'timestamp': datetime.now(),
        'original_token_count': count_tokens(old_messages)
    }

    return compressed
```

#### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏

```python
def update_memory_levels(self, new_message: str):
    """
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –ø–∞–º—è—Ç–∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ê–°–ò–ù–•–†–û–ù–ù–û.

    –í–∞–∂–Ω–æ: —ç—Ç–æ –ù–ï –±–ª–æ–∫–∏—Ä—É–µ—Ç inference!
    """

    # 1. –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ç–µ–∫—É—â—É—é –ø–∞–º—è—Ç—å
    self.current_memory.append(new_message)

    # 2. –ï—Å–ª–∏ —Ç–µ–∫—É—â–∞—è –ø–∞–º—è—Ç—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ (>250k —Ç–æ–∫–µ–Ω–æ–≤)
    if self.get_token_count(self.current_memory) > 250000:

        # –ê–°–ò–ù–•–†–û–ù–ù–û —Å–∂–∏–º–∞–µ–º –∏ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –≤ —É—Å—Ç–∞—Ä–µ–≤—à—É—é
        old_chunk = self.current_memory[:100]  # –ü–µ—Ä–≤—ã–µ 100 —Å–æ–æ–±—â–µ–Ω–∏–π

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–º–ø—Ä–µ—Å—Å–∏—é –≤ —Ñ–æ–Ω–µ (–Ω–µ –±–ª–æ–∫–∏—Ä—É—è inference)
        asyncio.create_task(
            self._compress_and_move_to_obsolete(old_chunk)
        )

        # –£–¥–∞–ª—è–µ–º –∏–∑ —Ç–µ–∫—É—â–µ–π –ø–∞–º—è—Ç–∏
        self.current_memory = self.current_memory[100:]

    # 3. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è —É—Å—Ç–∞—Ä–µ–≤—à–µ–π ‚Üí –¥–æ–ª–≥–æ–π –ø–∞–º—è—Ç–∏
    if self.get_token_count(self.obsolete_memory) > 250000:
        asyncio.create_task(
            self._compress_and_move_to_longterm()
        )
```

#### –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–í–ª–∏—è–Ω–∏–µ –Ω–∞ latency inference:**

```
–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ (8k –∫–æ–Ω—Ç–µ–∫—Å—Ç):
    Tokenization: 5ms
    Model Inference: 100ms
    Total: ~105ms

3-—É—Ä–æ–≤–Ω–µ–≤–∞—è –ø–∞–º—è—Ç—å (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ 12-15k –∫–æ–Ω—Ç–µ–∫—Å—Ç):
    Tokenization: 7ms (+2ms)
    Memory Search: 3-5ms (–ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫—É—Å–∫–æ–≤)
    Model Inference: 120ms (+20ms –∏–∑-–∑–∞ –±–æ–ª—å—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
    Total: ~130-135ms

–£–≤–µ–ª–∏—á–µ–Ω–∏–µ latency: ~25-30ms (20-25%)
```

**–ù–æ –≤—ã–∏–≥—Ä—ã—à –æ–≥—Ä–æ–º–µ–Ω:**
- –ö–ª–∞—Å—Å–∏–∫–∞: –ø–æ–º–Ω–∏—Ç —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 8k —Ç–æ–∫–µ–Ω–æ–≤
- –ù–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞: —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∏—Å—Ç–æ—Ä–∏–µ–π 750k —Ç–æ–∫–µ–Ω–æ–≤!

#### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ overhead:

1. **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞**
```python
@lru_cache(maxsize=1000)
def search_relevant(self, query: str, memory: list, max_tokens: int):
    """–ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –ø–æ—Ö–æ–∂–∏–º –∑–∞–ø—Ä–æ—Å–∞–º."""
    pass
```

2. **–í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ (–±—ã—Å—Ç—Ä—ã–π)**
```python
# –ò—Å–ø–æ–ª—å–∑—É–µ–º embeddings –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫—É—Å–∫–æ–≤
# –í–º–µ—Å—Ç–æ –ø–µ—Ä–µ–±–æ—Ä–∞ –≤—Å–µ—Ö 250k —Ç–æ–∫–µ–Ω–æ–≤ - –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–∞–º –∑–∞ O(log n)
from sentence_transformers import SentenceTransformer

class FastMemorySearch:
    def __init__(self):
        # –õ—ë–≥–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è embeddings
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')  # 80MB

    def search_relevant(self, query: str, memory_embeddings, top_k=5):
        """
        –ü–æ–∏—Å–∫ –∑–∞ ~3-5ms –≤–º–µ—Å—Ç–æ —Å–æ—Ç–µ–Ω –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥.

        1. –ü–æ–ª—É—á–∞–µ–º embedding –∑–∞–ø—Ä–æ—Å–∞ (2ms)
        2. Cosine similarity —Å–æ –≤—Å–µ–º–∏ –∫—É—Å–∫–∞–º–∏ –ø–∞–º—è—Ç–∏ (1-2ms)
        3. –í–æ–∑–≤—Ä–∞—â–∞–µ–º top-K —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö (1ms)
        """
        query_embedding = self.encoder.encode(query)
        similarities = cosine_similarity(query_embedding, memory_embeddings)
        top_indices = np.argsort(similarities)[-top_k:]
        return [memory[i] for i in top_indices]
```

3. **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è**
```python
# –ö–æ–º–ø—Ä–µ—Å—Å–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ —Ñ–æ–Ω–µ, –ù–ï –±–ª–æ–∫–∏—Ä—É—è –æ—Å–Ω–æ–≤–Ω—É—é —Ä–∞–±–æ—Ç—É
async def background_compression():
    while True:
        if needs_compression:
            await compress_old_memory()  # –ù–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç inference
        await asyncio.sleep(60)  # –ö–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É –ø—Ä–æ–≤–µ—Ä—è–µ–º
```

4. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª–µ–≥–∫–æ–≤–µ—Å–Ω–æ–π summarizer –º–æ–¥–µ–ª–∏**
```python
# –î–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ª–µ–Ω—å–∫—É—é –º–æ–¥–µ–ª—å (~500MB)
# –∞ –Ω–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ (~2GB)
self.summarizer = load_model('summarization-model-small')
```

#### –†–∞–∑–º–µ—Ä –ø–∞–º—è—Ç–∏ (RAM usage)

**–†–∞—Å—á—ë—Ç:**

```
–¢–µ–∫—É—â–∞—è –ø–∞–º—è—Ç—å: 250k —Ç–æ–∫–µ–Ω–æ–≤ * 2 bytes ‚âà 500 KB
–£—Å—Ç–∞—Ä–µ–≤—à–∞—è –ø–∞–º—è—Ç—å (—Å–∂–∞—Ç–∞—è): 250k —Ç–æ–∫–µ–Ω–æ–≤ * 2 bytes ‚âà 500 KB
–î–æ–ª–≥–∞—è –ø–∞–º—è—Ç—å (—É–ª—å—Ç—Ä–∞-—Å–∂–∞—Ç–∞—è): 250k —Ç–æ–∫–µ–Ω–æ–≤ * 2 bytes ‚âà 500 KB

Embeddings –¥–ª—è –ø–æ–∏—Å–∫–∞:
    - ~10k chunks * 384 dims * 4 bytes ‚âà 15 MB

Summarizer –º–æ–¥–µ–ª—å: ~500 MB (–∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏)

–ò—Ç–æ–≥–æ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤ RAM: ~1.5 MB + 15 MB = ~17 MB
–ü–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (–ø—Ä–∏ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏): +500 MB

–≠—Ç–æ –ù–ò–ß–¢–û–ñ–ù–û –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å —Ä–∞–∑–º–µ—Ä–æ–º —Å–∞–º–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (~1.5-2 GB –∫–∞–∂–¥—ã–π)!
```

#### –ò—Ç–æ–≥–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã:

‚úÖ **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
- –£–≤–µ–ª–∏—á–µ–Ω–∏–µ latency: ~20-30ms (–¥–æ–ø—É—Å—Ç–∏–º–æ –¥–ª—è —Ü–µ–ª–µ–≤—ã—Ö <200ms)
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∫–æ–º–ø—Ä–µ—Å—Å–∏—è –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç inference
- –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –¥–µ–ª–∞–µ—Ç –ø–æ–∏—Å–∫ –≤ –ø–∞–º—è—Ç–∏ –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä—ã–º

‚úÖ **–ü–∞–º—è—Ç—å (RAM):**
- Overhead: ~17 MB –ø–æ—Å—Ç–æ—è–Ω–Ω–æ (–Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ!)
- –ü–∏–∫–æ–≤–æ–µ: +500 MB –ø—Ä–∏ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏ (–≤—Ä–µ–º–µ–Ω–Ω–æ)

‚úÖ **–í—ã–∏–≥—Ä—ã—à:**
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: 750k —Ç–æ–∫–µ–Ω–æ–≤ vs –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö 8k
- –ú–æ–¥–µ–ª—å "–ø–æ–º–Ω–∏—Ç" –∏—Å—Ç–æ—Ä–∏—é –Ω–∞ 100x –±–æ–ª—å—à–µ
- –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞

‚úÖ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**
–°–∏—Å—Ç–µ–º–∞ –ø–∞–º—è—Ç–∏ –∞–±—Å–æ–ª—é—Ç–Ω–æ —Ä–µ–∞–ª–∏–∑—É–µ–º–∞ –±–µ–∑ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤–ª–∏—è–Ω–∏—è –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å!

## –ü–æ–¥—Ö–æ–¥—ã –∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (–¥–ª—è –±—É–¥—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)

### –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

1. **Quantization** - —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–µ–π
   - Q8: 8-bit quantization –¥–ª—è production
   - Q4: 4-bit quantization –¥–ª—è edge devices
   - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –≤–æ –≤—Ä–µ–º—è inference

2. **KV-Cache** - –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ keys –∏ values –∏–∑ attention
   - –£–º–µ–Ω—å—à–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –ø—Ä–∏ autoregressive generation

3. **Flash Attention** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è attention
   - O(n) memory –≤–º–µ—Å—Ç–æ O(n¬≤)
   - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è GPU

4. **Grouped-Query Attention (GQA)**
   - Sharing keys/values –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ query heads
   - –£–º–µ–Ω—å—à–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞

5. **Pruning** - —É–¥–∞–ª–µ–Ω–∏–µ –º–∞–ª–æ–∑–Ω–∞—á–∏–º—ã—Ö –≤–µ—Å–æ–≤
   - Structured pruning (—Ü–µ–ª—ã–µ —Å–ª–æ–∏/heads)
   - Unstructured pruning (–æ—Ç–¥–µ–ª—å–Ω—ã–µ –≤–µ—Å–∞)
   - –¶–µ–ª–µ–≤–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ: 20-30% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

6. **Knowledge Distillation**
   - –û–±—É—á–µ–Ω–∏–µ –º–∞–ª–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—ã—Ö–æ–¥–∞—Ö –±–æ–ª—å—à–æ–π
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ —É–º–µ–Ω—å—à–µ–Ω–∏–∏ —Ä–∞–∑–º–µ—Ä–∞

### –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

–ù–∞ CPU (Ryzen 5 4500U):
```
Text Generation: 100-200 tokens/sec
Latency (first token): <100ms
Memory Usage: <4GB RAM
Model Size: 1-2GB per expert (–ø–æ—Å–ª–µ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏)
```

–ù–∞ GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω):
```
Text Generation: 500+ tokens/sec
Latency (first token): <50ms
Memory Usage: <6GB VRAM
Batch Size: 4-8 –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
```

## –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–π API (–∫–æ–Ω—Ü–µ–ø—Ü–∏—è)

### –ü—Ä–æ—Å—Ç–æ–π Python API –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –º–æ–¥–µ–ª—å—é

```python
from moe_system import MoEClient

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞
client = MoEClient(model_path="models/")

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
response = client.generate(
    prompt="–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ Python –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ —Å–ø–∏—Å–∫–∞",
    max_tokens=200,
    temperature=0.7
)
print(response.text)

# –í—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
response = client.generate(
    prompt="–û–±—ä—è—Å–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤—É—é –º–µ—Ö–∞–Ω–∏–∫—É",
    expert="physics_expert",
    max_tokens=500
)

# –î–∏–∞–ª–æ–≥ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
conversation = client.start_conversation()
conversation.send("–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ —Ä–µ—à–∏—Ç—å –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ?")
conversation.send("–ê –µ—Å–ª–∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞–Ω—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π?")
```

### REST API (–±—É–¥—É—â–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞)

```bash
# –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ endpoints:

POST /generate              # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
POST /chat                  # –î–∏–∞–ª–æ–≥–æ–≤—ã–π —Ä–µ–∂–∏–º
GET  /experts               # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
POST /train                 # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–∞
GET  /status                # –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
```

## –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ª–∞–¥–∫–∞

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ

```python
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
logger.info("–≠–∫—Å–ø–µ—Ä—Ç –∑–∞–≥—Ä—É–∂–µ–Ω", extra={
    'expert_name': 'python_expert',
    'load_time_ms': 245.3,
    'parameters': '1.2B'
})

logger.debug("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Ç–µ–Ω–∑–æ—Ä–æ–≤", extra={
    'input_shape': [8, 512, 2048],
    'output_shape': [8, 512, 50000]
})

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫
logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏", extra={
    'model_path': 'models/expert.pt',
    'error': str(e)
})
```

### –û—Ç–ª–∞–¥–∫–∞ –º–æ–¥–µ–ª–µ–π

```python
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
def check_tensor_shapes(model_output, expected_shape):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤."""
    assert model_output.shape == expected_shape, \
        f"Expected {expected_shape}, got {model_output.shape}"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
def check_gradients(model):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤."""
    for name, param in model.named_parameters():
        if param.requires_grad and param.grad is None:
            logger.warning(f"No gradient for {name}")

# –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
import time

def benchmark_inference(model, input_text, num_runs=10):
    """–ó–∞–º–µ—Ä —Å–∫–æ—Ä–æ—Å—Ç–∏ inference."""
    times = []
    for _ in range(num_runs):
        start = time.time()
        output = model.generate(input_text)
        times.append(time.time() - start)

    avg_time = sum(times) / len(times)
    logger.info(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è inference: {avg_time*1000:.2f}ms")
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏

```python
def evaluate_model(model, test_dataset):
    """
    –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

    –ú–µ—Ç—Ä–∏–∫–∏:
        - Perplexity
        - Accuracy (–¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
        - BLEU/ROUGE (–¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞)
    """
    model.eval()
    total_loss = 0

    with torch.no_grad():
        for batch in test_dataset:
            outputs = model(batch['input_ids'])
            loss = compute_loss(outputs, batch['labels'])
            total_loss += loss.item()

    perplexity = math.exp(total_loss / len(test_dataset))
    logger.info(f"Perplexity: {perplexity:.2f}")

    return perplexity
```

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–∫–æ–Ω—Ü–µ–ø—Ü–∏—è)

### –ü—Ä–æ—Å—Ç–æ–π –¥–∏–∞–ª–æ–≥

```python
from moe_system import MoEClient

client = MoEClient()

# –í–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
response = client.generate("–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?")
print(response.text)

# –õ–æ–≥–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞
response = client.generate(
    "–£ –ú–∞—à–∏ –±—ã–ª–æ 5 —è–±–ª–æ–∫. –û–Ω–∞ –¥–∞–ª–∞ 2 —è–±–ª–æ–∫–∞ –ü–µ—Ç–µ. –°–∫–æ–ª—å–∫–æ —è–±–ª–æ–∫ –æ—Å—Ç–∞–ª–æ—Å—å —É –ú–∞—à–∏?"
)
print(response.text)  # –û–∂–∏–¥–∞–µ—Ç—Å—è: "–£ –ú–∞—à–∏ –æ—Å—Ç–∞–ª–æ—Å—å 3 —è–±–ª–æ–∫–∞"
```

### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞

```python
# –ó–∞–ø—Ä–æ—Å –∫ —ç–∫—Å–ø–µ—Ä—Ç—É –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é
code_prompt = """
–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞ Python, –∫–æ—Ç–æ—Ä–∞—è:
1. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª
2. –§–∏–ª—å—Ç—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ —á–µ—Ç–Ω—ã–µ —á–∏—Å–ª–∞
3. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ö —Å—É–º–º—É
"""

response = client.generate(
    prompt=code_prompt,
    expert="python_expert",
    max_tokens=200
)
print(response.text)
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏

```python
# –ó–∞–ø—Ä–æ—Å –∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É —ç–∫—Å–ø–µ—Ä—Ç—É
math_prompt = "–ù–∞–π–¥–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é —Ñ—É–Ω–∫—Ü–∏–∏ f(x) = 3x^2 + 2x - 5"

response = client.generate(
    prompt=math_prompt,
    expert="mathematics_expert"
)
print(response.text)  # –û–∂–∏–¥–∞–µ—Ç—Å—è: "f'(x) = 6x + 2"
```

### –û–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞

```python
from moe_system.training import ExpertTrainer

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = {
    'name': 'rust_expert',
    'domain': 'Rust Programming',
    'd_model': 2048,
    'n_layers': 8,
    'n_heads': 16
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è trainer
trainer = ExpertTrainer(config)

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
train_data = load_dataset('rust_code_examples.jsonl')

# –û–±—É—á–µ–Ω–∏–µ
trainer.train(
    train_data=train_data,
    epochs=10,
    batch_size=4,
    learning_rate=1e-4
)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
trainer.save('models/experts/rust_expert/')
```

## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª: `config.yaml`

```yaml
# –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
experts:
  model_dir: "models/experts"
  cache_size: 3                    # –ú–∞–∫—Å —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ –ø–∞–º—è—Ç–∏
  default_quantization: "Q8"       # Q8 –∏–ª–∏ Q4

router:
  strategy: "learned"              # learned, rule_based, hierarchical
  confidence_threshold: 0.5

multimodal:
  vision:
    enabled: true
    device: "cpu"                  # cpu –∏–ª–∏ cuda
  motor:
    enabled: false                 # true –¥–ª—è hardware
    config_file: "configs/robot_config.yaml"

api:
  workers: 4                       # Uvicorn workers
```

## –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –ù–∞ CPU (Ryzen 5 4500U)

```
Text Generation:     100-200 tok/s
First Token Latency: <100ms
Total Memory:        <4GB
Per Expert Memory:   ~1.5GB (–ø–æ—Å–ª–µ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏)
CPU Usage:           <70%
```

### –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏

```
Perplexity:          <15 (–Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ)
–õ–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏:   >90% accuracy
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞:      >85% compilable & correct
–ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: >90% –≤ –¥–∏–∞–ª–æ–≥–µ
```

### –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å Router

```
Selection Time:      <10ms
Accuracy:            >95% (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —ç–∫—Å–ø–µ—Ä—Ç –≤—ã–±—Ä–∞–Ω)
Confidence:          >0.8 (—Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)
```

## –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞

**–í–°–Ø –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –ù–ê–•–û–î–ò–¢–°–Ø –í –ü–ê–ü–ö–ï `docs/`**

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

```
docs/
‚îú‚îÄ‚îÄ Plans/         # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–ª–∞–Ω—ã –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îú‚îÄ‚îÄ Progress/      # –°—Ç–∞—Ç—É—Å –ø—Ä–æ–µ–∫—Ç–∞ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
‚îú‚îÄ‚îÄ Reports/       # –û—Ç—á—ë—Ç—ã –ø–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–º —ç—Ç–∞–ø–∞–º —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
‚îî‚îÄ‚îÄ *.md           # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º —Å–∏—Å—Ç–µ–º—ã
```

### üìÅ Plans/ - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–ª–∞–Ω—ã

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –¥–∏–∑–∞–π–Ω —Å–∏—Å—Ç–µ–º—ã

- **20260106_ARCHITECTURE.md** - –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ MoE –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
  - Transformer –±–ª–æ–∫–∏ –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞
  - Router —Å–∏—Å—Ç–µ–º–∞ (Learned, Rule-Based, Hierarchical)
  - Expert management
  - Multimodal integration (–±—É–¥—É—â–µ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ)

- **20260106_README.md** - –æ–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞
  - –û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ MoE
  - Roadmap —Ä–∞–∑–≤–∏—Ç–∏—è
  - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

- **20260106_API_REFERENCE.md** - API —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è
  - –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ REST API endpoints
  - Python SDK API
  - –§–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤

- **20260106_INSTALLATION.md** - —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ
  - –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
  - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
  - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã

- **20260106_HARDWARE_GUIDE.md** - hardware –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
  - –î–ª—è embodied AI (–±—É–¥—É—â–µ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ)
  - –†–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞ –∏ –º–æ—Ç–æ—Ä–∏–∫–∞

### üìÅ Progress/ - –°—Ç–∞—Ç—É—Å –∏ –ø—Ä–æ–≥—Ä–µ—Å—Å

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞

- **PROJECT_STATUS.md** ‚≠ê **–ì–õ–ê–í–ù–´–ô –§–ê–ô–õ –°–¢–ê–¢–£–°–ê**
  - –¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–æ–µ–∫—Ç–∞
  - –ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (‚úÖ)
  - –ß—Ç–æ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ (üöß)
  - –°–ª–µ–¥—É—é—â–∏–µ –∑–∞–¥–∞—á–∏
  - –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
  - **–í–°–ï–ì–î–ê –ø—Ä–æ–≤–µ—Ä—è–π —ç—Ç–æ—Ç —Ñ–∞–π–ª –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è!**

- **README.md** - –æ–ø–∏—Å–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

### üìÅ Reports/ - –û—Ç—á—ë—Ç—ã –ø–æ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:** –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á—ë—Ç—ã –æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö

- **PROJECT_SUMMARY.md** - –∏—Ç–æ–≥–∏ Milestone 1
  - TransformerBlock —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
  - ThreeLevelMemory —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

- **EXPERT_MODEL_IMPLEMENTATION.md** - –æ—Ç—á—ë—Ç –ø–æ ExpertModel
  - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
  - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
  - –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

- **ROUTER_IMPLEMENTATION.md** - –æ—Ç—á—ë—Ç –ø–æ SimpleRouter
  - –ê–ª–≥–æ—Ä–∏—Ç–º –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
  - –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
  - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π

### üìÑ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ (–≤ –∫–æ—Ä–Ω–µ docs/)

- **EXPERT_MODEL.md** - –ø–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è ExpertModel
  - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
  - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
  - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (Tiny, Small, Medium, Large)
  - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ

- **ROUTER.md** - –ø–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è SimpleRouter
  - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
  - –ê–ª–≥–æ—Ä–∏—Ç–º scoring
  - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
  - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å MoE —Å–∏—Å—Ç–µ–º–æ–π

- **README.md** - –æ–±–∑–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

### üîç –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏

**–ù—É–∂–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞?**
‚Üí `docs/Progress/PROJECT_STATUS.md`

**–ù—É–∂–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –¥–µ—Ç–∞–ª–∏?**
‚Üí `docs/Plans/20260106_ARCHITECTURE.md`

**–ù—É–∂–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—É?**
‚Üí `docs/EXPERT_MODEL.md` –∏–ª–∏ `docs/ROUTER.md`

**–ù—É–∂–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤ –∏ –æ—Ç—á—ë—Ç—ã?**
‚Üí `docs/Reports/`

## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

### Core –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (—Ç–µ–∫—É—â–∏–µ)

```bash
# –û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ AI
torch>=2.0.0              # PyTorch –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π
transformers>=4.35.0      # Hugging Face Transformers
numpy>=1.24.0             # –ß–∏—Å–ª–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
```

### Development –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```bash
# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞
pytest>=7.4.0             # Unit —Ç–µ—Å—Ç—ã
black>=23.0.0             # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
flake8>=6.0.0             # –õ–∏–Ω—Ç–∏–Ω–≥
mypy>=1.5.0               # Type checking

# –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
jupyter>=1.0.0            # Jupyter notebooks
matplotlib>=3.7.0         # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
tensorboard>=2.14.0       # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è
```

### –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)

```bash
# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è inference
onnx>=1.14.0              # ONNX export
onnxruntime>=1.16.0       # ONNX runtime

# –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è
accelerate>=0.23.0        # Distributed training
bitsandbytes>=0.41.0      # –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è
```

### –ë—É–¥—É—â–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```bash
# Multimodal (–≤ –ø–ª–∞–Ω–∞—Ö)
opencv-python>=4.8.0      # Vision
pillow>=10.0.0            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
whisper                   # Audio (Speech recognition)

# Infrastructure (–¥–ª—è production)
fastapi>=0.104.0          # REST API
uvicorn>=0.24.0           # ASGI server
pydantic>=2.4.0           # Data validation

# Database (–¥–ª—è production)
sqlalchemy>=2.0.0         # ORM
psycopg2>=2.9.0          # PostgreSQL
redis>=5.0.0              # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
```

## Workflow —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

### –¢–µ–∫—É—â–∏–π —ç—Ç–∞–ø: –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ

1. **–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä**
   - –ò–∑—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö MoE –ø–æ–¥—Ö–æ–¥–æ–≤
   - –ü—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ router —Å–∏—Å—Ç–µ–º—ã
   - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤

2. **–ü—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ notebooks**
   - Jupyter notebooks –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
   - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤
   - –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–π

3. **–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤**
   - –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Transformer –±–ª–æ–∫–æ–≤
   - –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ Router –ª–æ–≥–∏–∫–∏
   - Expert management —Å–∏—Å—Ç–µ–º–∞

4. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –∏—Ç–µ—Ä–∞—Ü–∏—è**
   - Unit —Ç–µ—Å—Ç—ã –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
   - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π —Ç–µ–Ω–∑–æ—Ä–æ–≤
   - –í–∞–ª–∏–¥–∞—Ü–∏—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π

5. **–î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**
   - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
   - –ö–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
   - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –°—Ç–∞–Ω–¥–∞—Ä—Ç—ã –ø—Ä–∏ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ –∫–æ–¥–∞

‚úÖ **–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ:**
- Type hints –¥–ª—è –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π
- Docstrings –≤ Google Style –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö
- Unit —Ç–µ—Å—Ç—ã –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ

‚úÖ **–ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ:**
- –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ docstrings
- –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

## –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –ø—Ä–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ

1. **–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å** - –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
2. **–ß–∏—Ç–∞–µ–º–æ—Å—Ç—å** - –ø–æ–Ω—è—Ç–Ω—ã–π –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥
3. **–¢–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** - –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
4. **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å inference
5. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ –ø—Ä–æ–µ–∫—Ç–∞

### –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ (–±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è)
- [ ] –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ Transformer –±–ª–æ–∫–∞
- [ ] –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ Router (rule-based)
- [ ] –ü—Ä–æ—Ç–æ—Ç–∏–ø –æ–¥–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
- [ ] Inference pipeline –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- [ ] –ë–∞–∑–æ–≤—ã–µ unit —Ç–µ—Å—Ç—ã

### –°—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω—ã–µ (—Å–ª–µ–¥—É—é—â–∏–µ —ç—Ç–∞–ø—ã)
- [ ] –û–±—É—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- [ ] –†–µ–∞–ª–∏–∑–∞—Ü–∏—è learned router
- [ ] –°–∏—Å—Ç–µ–º–∞ –∑–∞–≥—Ä—É–∑–∫–∏/–≤—ã–≥—Ä—É–∑–∫–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (lazy loading)
- [ ] API –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π
- [ ] Benchmark –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ (–±—É–¥—É—â–µ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ)
- [ ] Multimodal –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ (Vision, Audio)
- [ ] Embodied AI –∏ hardware –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
- [ ] Federated learning –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
- [ ] Production deployment
- [ ] –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–æ 64+ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
