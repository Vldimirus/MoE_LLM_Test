"""
–£–ø—Ä–æ—â—ë–Ω–Ω–∞—è UI –ø–∞–Ω–µ–ª—å –¥–ª—è Transfer Learning –∏–∑ GGUF –º–æ–¥–µ–ª–µ–π.

–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:
    - –í—ã–±–æ—Ä GGUF –º–æ–¥–µ–ª–∏ (–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É)
    - –í—ã–±–æ—Ä —ç–∫—Å–ø–µ—Ä—Ç–∞ (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–ª–∏ –Ω–æ–≤—ã–π)
    - –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    - –ö–Ω–æ–ø–∫–∞ "–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è"
    - Progress bar —Å –æ–±—Ä–∞—Ç–Ω—ã–º –æ—Ç—Å—á—ë—Ç–æ–º –∏ % –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
"""

import gradio as gr
from pathlib import Path
from typing import Optional, Dict
import time
import os
import sys
import torch
import json
from datetime import timedelta

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from transfer_learning import TransferLearningPipeline


def create_transfer_learning_panel(moe_system):
    """
    –°–æ–∑–¥–∞—ë—Ç –£–ü–†–û–©–Å–ù–ù–£–Æ UI –ø–∞–Ω–µ–ª—å –¥–ª—è Transfer Learning.

    Args:
        moe_system: –≠–∫–∑–µ–º–ø–ª—è—Ä MoESystem

    Returns:
        Gradio –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –≤–∫–ª–∞–¥–∫–∏
    """

    # –§—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
    def get_available_experts() -> list:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤."""
        experts_dir = Path("models/experts")
        if not experts_dir.exists():
            return []

        experts = []
        for expert_path in experts_dir.iterdir():
            if expert_path.is_dir() and (expert_path / "metadata.json").exists():
                experts.append(expert_path.name)
        return experts

    # –§—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
    def estimate_time(gguf_path: str) -> str:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤—Ä–µ–º—è transfer learning –ø—Ä–æ—Ü–µ—Å—Å–∞.

        Args:
            gguf_path: –ü—É—Ç—å –∫ GGUF —Ñ–∞–π–ª—É

        Returns:
            –°—Ç—Ä–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–∞–∑–º–µ—Ä–µ —Ñ–∞–π–ª–∞
        """
        try:
            if not gguf_path or not os.path.exists(gguf_path):
                return "‚ùì –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ GGUF —Ñ–∞–π–ª—É"

            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size_gb = os.path.getsize(gguf_path) / (1024**3)

            # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞: ~1-2 –º–∏–Ω—É—Ç—ã –Ω–∞ 1GB
            # (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç CPU, –Ω–æ —ç—Ç–æ —Ä–∞–∑—É–º–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
            estimated_seconds = int(file_size_gb * 90)  # 90 —Å–µ–∫ –Ω–∞ 1GB

            # –ú–∏–Ω–∏–º—É–º 30 —Å–µ–∫—É–Ω–¥, –º–∞–∫—Å–∏–º—É–º 30 –º–∏–Ω—É—Ç
            estimated_seconds = max(30, min(estimated_seconds, 1800))

            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤ —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥
            if estimated_seconds < 60:
                time_str = f"{estimated_seconds} —Å–µ–∫—É–Ω–¥"
            elif estimated_seconds < 3600:
                minutes = estimated_seconds // 60
                time_str = f"~{minutes} –º–∏–Ω—É—Ç"
            else:
                hours = estimated_seconds // 3600
                time_str = f"~{hours} —á–∞—Å–æ–≤"

            return f"‚è±Ô∏è **–ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è:** {time_str}\n\nüì¶ **–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞:** {file_size_gb:.2f} GB"

        except Exception as e:
            return f"‚ùå **–û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏:** {str(e)}"

    # –ì–ª–∞–≤–Ω—ã–π UI
    gr.Markdown("## üîÑ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –∏–∑ GGUF –º–æ–¥–µ–ª–∏")
    gr.Markdown("""
    **–ü—Ä–æ—Ü–µ—Å—Å transfer learning:**
    1. –£–∫–∞–∑—ã–≤–∞–µ—Ç–µ –ø—É—Ç—å –∫ GGUF –º–æ–¥–µ–ª–∏ (Phi-3, Llama, Mistral, –∏ —Ç.–¥.)
    2. –í—ã–±–∏—Ä–∞–µ—Ç–µ —ç–∫—Å–ø–µ—Ä—Ç–∞ (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–ª–∏ —Å–æ–∑–¥–∞—ë—Ç–µ –Ω–æ–≤–æ–≥–æ)
    3. –ù–∞–∂–∏–º–∞–µ—Ç–µ "–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è"
    4. –°–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç –≤–µ—Å–∞ –∏–∑ GGUF –≤ –≤–∞—à–µ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞

    –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç –º–æ–∂–Ω–æ –¥–æ–æ–±—É—á–∏—Ç—å –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤–∫–ª–∞–¥–∫–µ **üéì Training**.
    """)

    with gr.Row():
        with gr.Column(scale=2):
            # === –°–µ–∫—Ü–∏—è 1: –í—ã–±–æ—Ä GGUF –º–æ–¥–µ–ª–∏ ===
            gr.Markdown("### 1Ô∏è‚É£ GGUF –º–æ–¥–µ–ª—å (–∏—Å—Ç–æ—á–Ω–∏–∫ –∑–Ω–∞–Ω–∏–π)")

            gguf_path = gr.Textbox(
                label="–ü—É—Ç—å –∫ GGUF —Ñ–∞–π–ª—É",
                placeholder="models/gguf/phi-3-mini-4k-instruct-q8_0.gguf",
                info="–£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ GGUF –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∏—Å–∫–µ"
            )

            # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
            estimate_btn = gr.Button("üìä –û—Ü–µ–Ω–∏—Ç—å –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", size="sm")

            time_estimation = gr.Markdown(value="", visible=True)

            gr.Markdown("---")

            # === –°–µ–∫—Ü–∏—è 2: –í—ã–±–æ—Ä —ç–∫—Å–ø–µ—Ä—Ç–∞ ===
            gr.Markdown("### 2Ô∏è‚É£ –¶–µ–ª–µ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç (–∫—É–¥–∞ –∫–æ–ø–∏—Ä—É–µ–º –∑–Ω–∞–Ω–∏—è)")

            expert_mode = gr.Radio(
                choices=["–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞", "–û–±–Ω–æ–≤–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ"],
                value="–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞",
                label="–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"
            )

            # –î–ª—è –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
            with gr.Group(visible=True) as new_expert_group:
                new_expert_id = gr.Textbox(
                    label="ID –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞",
                    placeholder="python_expert",
                    info="–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–ª–∞—Ç–∏–Ω–∏—Ü–∞, –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤)"
                )

                new_expert_name = gr.Textbox(
                    label="–ù–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞",
                    placeholder="Python Programming Expert",
                    info="–ß–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º–æ–µ –∏–º—è"
                )

            # –î–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
            with gr.Group(visible=False) as existing_expert_group:
                existing_expert_id = gr.Dropdown(
                    choices=get_available_experts(),
                    label="–í—ã–±–µ—Ä–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞",
                    info="‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –≤–µ—Å–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞ –±—É–¥—É—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω—ã!"
                )

                refresh_experts_btn = gr.Button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫", size="sm")

            # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏
            def toggle_expert_mode(mode):
                if mode == "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞":
                    return gr.update(visible=True), gr.update(visible=False)
                else:
                    return gr.update(visible=False), gr.update(visible=True)

            expert_mode.change(
                fn=toggle_expert_mode,
                inputs=[expert_mode],
                outputs=[new_expert_group, existing_expert_group]
            )

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
            def refresh_experts():
                experts = get_available_experts()
                return gr.update(choices=experts)

            refresh_experts_btn.click(
                fn=refresh_experts,
                outputs=[existing_expert_id]
            )

        with gr.Column(scale=1):
            # === –°–µ–∫—Ü–∏—è 3: –ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ ===
            gr.Markdown("### 3Ô∏è‚É£ –ó–∞–ø—É—Å–∫")

            start_btn = gr.Button(
                "üöÄ –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∑–Ω–∞–Ω–∏—è",
                variant="primary",
                size="lg"
            )

            gr.Markdown("---")

            # Progress –∏ —Å—Ç–∞—Ç—É—Å
            gr.Markdown("### üìä –ü—Ä–æ–≥—Ä–µ—Å—Å")

            # Countdown timer
            countdown_display = gr.Textbox(
                label="–û—Å—Ç–∞–ª–æ—Å—å –≤—Ä–µ–º–µ–Ω–∏",
                value="--:--",
                interactive=False
            )

            # Percentage
            percentage_display = gr.Textbox(
                label="–í—ã–ø–æ–ª–Ω–µ–Ω–æ",
                value="0%",
                interactive=False
            )

            # –î–µ—Ç–∞–ª—å–Ω—ã–π –ª–æ–≥
            status_log = gr.Textbox(
                label="–õ–æ–≥ –ø—Ä–æ—Ü–µ—Å—Å–∞",
                lines=12,
                interactive=False,
                value="–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞..."
            )

            # –†–µ–∑—É–ª—å—Ç–∞—Ç
            result_message = gr.Markdown(visible=False)

    # === Backend —Ñ—É–Ω–∫—Ü–∏–∏ ===

    # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
    estimate_btn.click(
        fn=estimate_time,
        inputs=[gguf_path],
        outputs=[time_estimation]
    )

    # –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è transfer learning —Å progress tracking
    def run_transfer_learning(
        gguf_path: str,
        expert_mode: str,
        new_expert_id: str,
        new_expert_name: str,
        existing_expert_id: str,
        progress=gr.Progress()
    ):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç transfer learning —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –∏ countdown.
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º expert_id
            if expert_mode == "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞":
                if not new_expert_id:
                    return (
                        "‚ùå –û—à–∏–±–∫–∞: —É–∫–∞–∂–∏—Ç–µ ID –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞",
                        "--:--",
                        "0%",
                        gr.update(visible=False)
                    )
                expert_id = new_expert_id
                expert_name = new_expert_name if new_expert_name else new_expert_id
            else:
                if not existing_expert_id:
                    return (
                        "‚ùå –û—à–∏–±–∫–∞: –≤—ã–±–µ—Ä–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞",
                        "--:--",
                        "0%",
                        gr.update(visible=False)
                    )
                expert_id = existing_expert_id
                expert_name = expert_id

            # –í–∞–ª–∏–¥–∞—Ü–∏—è GGUF path
            if not gguf_path or not os.path.exists(gguf_path):
                return (
                    f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {gguf_path}",
                    "--:--",
                    "0%",
                    gr.update(visible=False)
                )

            # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
            file_size_gb = os.path.getsize(gguf_path) / (1024**3)
            estimated_seconds = int(file_size_gb * 90)  # 90 —Å–µ–∫ –Ω–∞ 1GB
            estimated_seconds = max(30, min(estimated_seconds, 1800))
            start_time = time.time()

            # –≠—Ç–∞–ø 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (5% - 10 —Å–µ–∫)
            progress(0.05, desc="–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pipeline...")
            log = f"üöÄ –ó–∞–ø—É—Å–∫ transfer learning\n"
            log += f"GGUF: {gguf_path}\n"
            log += f"–≠–∫—Å–ø–µ—Ä—Ç: {expert_id}\n"
            log += f"–û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏: ~{estimated_seconds}s\n\n"

            elapsed = int(time.time() - start_time)
            remaining = max(0, estimated_seconds - elapsed)
            countdown = str(timedelta(seconds=remaining))

            yield (log, countdown, "5%", gr.update(visible=False))
            time.sleep(2)

            # –°–æ–∑–¥–∞—ë–º pipeline
            pipeline = TransferLearningPipeline(
                gguf_path=gguf_path,
                target_model_config={
                    'vocab_size': 8000,
                    'd_model': 2048,     # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Llama-3.2!
                    'n_layers': 8,       # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 6 –¥–æ 8
                    'n_heads': 16,       # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 8 –¥–æ 16
                    'd_ff': 8192,        # 4 * d_model
                    'max_seq_len': 512
                },
                bpe_tokenizer_path="models/tokenizers/bpe_multilang.model"
            )

            # –≠—Ç–∞–ø 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (10% - 15 —Å–µ–∫)
            progress(0.10, desc="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏...")
            log += "üìä –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏...\n"

            elapsed = int(time.time() - start_time)
            remaining = max(0, estimated_seconds - elapsed)
            countdown = str(timedelta(seconds=remaining))

            yield (log, countdown, "10%", gr.update(visible=False))

            compat = pipeline.validate_compatibility()

            if not compat['compatible']:
                log += f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:\n"
                for warning in compat.get('warnings', []):
                    log += f"  - {warning}\n"
                log += "\n–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —ç—Ç–∏–º–∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏...\n\n"
            else:
                log += f"‚úÖ –°–æ–≤–º–µ—Å—Ç–∏–º–æ! Vocab overlap: {compat['vocab_overlap']:.1%}\n\n"

            elapsed = int(time.time() - start_time)
            remaining = max(0, estimated_seconds - elapsed)
            countdown = str(timedelta(seconds=remaining))

            yield (log, countdown, "15%", gr.update(visible=False))
            time.sleep(1)

            # –≠—Ç–∞–ø 3: –ü–∞—Ä—Å–∏–Ω–≥ GGUF (30% - 30 —Å–µ–∫)
            progress(0.30, desc="–ü–∞—Ä—Å–∏–Ω–≥ GGUF –º–æ–¥–µ–ª–∏...")
            log += "üì¶ –ü–∞—Ä—Å–∏–Ω–≥ GGUF —Ñ–∞–π–ª–∞...\n"

            elapsed = int(time.time() - start_time)
            remaining = max(0, estimated_seconds - elapsed)
            countdown = str(timedelta(seconds=remaining))

            yield (log, countdown, "30%", gr.update(visible=False))
            time.sleep(3)

            # –≠—Ç–∞–ø 4: Transfer –≤–µ—Å–æ–≤ (70% - 60 —Å–µ–∫)
            progress(0.40, desc="–ü–µ—Ä–µ–Ω–æ—Å –≤–µ—Å–æ–≤ (—Å–ª–æ–π 1/6)...")
            log += "üîÑ –ü–µ—Ä–µ–Ω–æ—Å –≤–µ—Å–æ–≤ –∏–∑ GGUF –≤ ExpertModel...\n"

            model = pipeline.initialize_model_from_gguf(
                layers_to_transfer=[0, 1, 2, 3, 4, 5, 6, 7],
                freeze_transferred_layers=True,
                align_embeddings=True
            )

            # –°–∏–º—É–ª—è—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ —Å–ª–æ—è–º
            for layer in range(8):
                progress_val = 0.40 + (layer / 8) * 0.30
                progress(progress_val, desc=f"–ü–µ—Ä–µ–Ω–æ—Å –≤–µ—Å–æ–≤ (—Å–ª–æ–π {layer+1}/8)...")
                log += f"  ‚úì –°–ª–æ–π {layer} –ø–µ—Ä–µ–Ω–µ—Å—ë–Ω\n"

                elapsed = int(time.time() - start_time)
                remaining = max(0, estimated_seconds - elapsed)
                countdown = str(timedelta(seconds=remaining))
                percent = f"{int(progress_val * 100)}%"

                yield (log, countdown, percent, gr.update(visible=False))
                time.sleep(1)

            log += "‚úÖ –í—Å–µ —Å–ª–æ–∏ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã!\n\n"

            # –≠—Ç–∞–ø 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (90% - 70 —Å–µ–∫)
            progress(0.90, desc="–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞...")
            log += "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...\n"

            output_dir = Path(f"models/experts/{expert_id}")
            output_dir.mkdir(parents=True, exist_ok=True)

            # Checkpoint
            checkpoint = {
                'model_state_dict': model.state_dict(),
                'config': {
                    'vocab_size': 8000,
                    'd_model': 2048,
                    'n_layers': 8,
                    'n_heads': 16,
                    'd_ff': 8192,
                    'max_seq_len': 512
                },
                'expert_id': expert_id,
                'source_gguf': gguf_path,
                'transfer_config': {
                    'layers_to_transfer': [0, 1, 2, 3, 4, 5, 6, 7],
                    'freeze_transferred': True
                }
            }

            torch.save(checkpoint, output_dir / "model.pt")

            # Metadata
            metadata = {
                "expert_id": expert_id,
                "name": expert_name,
                "source_gguf": gguf_path,
                "vocab_overlap": compat['vocab_overlap'],
                "transferred_layers": [0, 1, 2, 3, 4, 5, 6, 7],
                "architecture": checkpoint['config'],
                "type": "transferred_model",
                "version": "1.0.0-gguf"
            }

            with open(output_dir / "metadata.json", 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            # Tokenizer config
            tokenizer_config = {
                "tokenizer_type": "bpe",
                "model_path": "models/tokenizers/bpe_multilang.model",
                "vocab_size": 8000,
                "pad_token_id": 0,
                "unk_token_id": 1,
                "bos_token_id": 2,
                "eos_token_id": 3
            }
            with open(output_dir / "tokenizer_config.json", 'w', encoding='utf-8') as f:
                json.dump(tokenizer_config, f, indent=2, ensure_ascii=False)

            log += f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {output_dir}\n\n"

            elapsed = int(time.time() - start_time)
            remaining = max(0, estimated_seconds - elapsed)
            countdown = str(timedelta(seconds=remaining))

            yield (log, countdown, "95%", gr.update(visible=False))
            time.sleep(1)

            # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ (100%)
            progress(1.0, desc="–ì–æ—Ç–æ–≤–æ!")
            log += "=" * 50 + "\n"
            log += "üéâ Transfer Learning –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!\n"
            log += f"–≠–∫—Å–ø–µ—Ä—Ç: {expert_id}\n"
            log += f"–ü—É—Ç—å: {output_dir}\n"
            log += f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {int(time.time() - start_time)}s\n"

            success_msg = f"""
‚úÖ **–£—Å–ø–µ—à–Ω–æ!**

**–≠–∫—Å–ø–µ—Ä—Ç:** `{expert_id}`
**–ü—É—Ç—å:** `{output_dir}`
**–í—Ä–µ–º—è:** {int(time.time() - start_time)}s
**Vocab overlap:** {compat['vocab_overlap']:.1%}

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

1. **Fine-tuning**: –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤–æ –≤–∫–ª–∞–¥–∫—É **üéì Training** –∏ –¥–æ–æ–±—É—á–∏—Ç–µ —ç–∫—Å–ø–µ—Ä—Ç–∞ –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö
2. **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤–æ –≤–∫–ª–∞–¥–∫—É **üí¨ Chat** –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–æ–±—â–∞—Ç—å—Å—è —Å —ç–∫—Å–ø–µ—Ä—Ç–æ–º
"""

            yield (log, "00:00:00", "100%", gr.update(value=success_msg, visible=True))

        except Exception as e:
            import traceback
            error_log = f"‚ùå –û–®–ò–ë–ö–ê:\n{str(e)}\n\n{traceback.format_exc()}"
            yield (error_log, "--:--", "0%", gr.update(visible=False))

    # –ü—Ä–∏–≤—è–∑–∫–∞ —Å–æ–±—ã—Ç–∏–π
    start_btn.click(
        fn=run_transfer_learning,
        inputs=[
            gguf_path,
            expert_mode,
            new_expert_id,
            new_expert_name,
            existing_expert_id
        ],
        outputs=[status_log, countdown_display, percentage_display, result_message]
    )
